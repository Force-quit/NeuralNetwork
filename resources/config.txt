# File that contains the training data set.
datafile=mnist-ubyte

# The shape of a new neural network
# Comma separated list of the layers sizes (e.g. 16,4,4,3 or 1,1,1).
#     First layer is the input neurons.
#     Last layer is the output layer.
# The default value is '[]'.
layers=784,20,20,10

# Export the neural network after training.
export=nn_fully_trained

# Choice of activation function
# Available values are
#    Sigmoid(k), Logistic function with stepness ``k``.
#    ReLU,       Rectified linear unit.
#    LeakyReLY,  Leaky ReLU, like ReLU but with small gradiant (1/100)
# The default value is 'Sigmoid(1)'.
activation=Sigmoid(1)

# Maximum number of iterations
# The training will stop after that much iterations completed 
# Note that `-1` stands for `2^64-1`.
# The default value is '100'.
maxEpoch=100

# Learning rate
# Multiplicative coefficient on error gradient.
# The default value is '0.010000'.
# learningRate=0.01

# Momentum
# Multiplicative coefficient applied on previous error delta when non using
# batch learning.
# The default value is '0.900000'.
# momentum=0.9

# Batch learning
# The learning program uses batch learning or not (1 : yes, 0 : no).
# The default value is '0'.
# batchLearning=0

# Accuracy
# Desired accuracy. Training stops when the desired accuracy is obtained.
# The default value is '95.000000'.
accuracy=99.0

# Labels for output nodes. Comma separated list of work without white spaces.
# Only for new networks and is only used with the GUI visualization tool.
# The default value is ''.
labels=0,1,2,3,4,5,6,7,8,9

# Verbosity level
#    Level 0: quiet mode.
#    Level 1: prints training evolution.
#    Level 2: prints NN at initialization and at the end.
#    Level 3: prints NN at every iteration of the learning phase.
verbosity=1